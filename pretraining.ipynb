{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 03:51:12.937958: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-17 03:51:12.937999: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "nltk.download('punkt')\n",
    "import numpy as np\n",
    "from nltk.corpus import words\n",
    "nltk.download('words')\n",
    "from nltk.corpus import brown\n",
    "nltk.download('brown')\n",
    "from numpy import genfromtxt\n",
    "from tensorflow.keras import regularizers\n",
    "import time\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"file_lst.pkl\", \"rb\") as f:\n",
    "    lst_from_pkl = pickle.load(f)\n",
    "random.shuffle(lst_from_pkl)\n",
    "sentence_label_array = []\n",
    "\n",
    "for name in lst_from_pkl:\n",
    "    idx = name.index(\"_\")\n",
    "    label = int(name[:idx]) + 1\n",
    "    with open(name, 'r') as file:\n",
    "        data = [line.strip() for line in file.readlines()]\n",
    "    labels = [label] * len(data)\n",
    "    sentence_label_array.extend([(data[i],labels[i]) for i in range(len(data))])\n",
    "\n",
    "random.shuffle(sentence_label_array)\n",
    "text_train, text_test = train_test_split(sentence_label_array, test_size=0.1)\n",
    "\n",
    "X_train = [group[0] for group in text_train]\n",
    "y_train = np.array([group[1] for group in text_train])\n",
    "X_test = [group[0] for group in text_test]\n",
    "y_test = np.array([group[1] for group in text_test])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "with open('tokenizer.pkl','wb') as f:\n",
    "    pickle.dump(tokenizer,f)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_train_seq_padded = pad_sequences(X_train_seq, maxlen=500)\n",
    "X_test_seq_padded  = pad_sequences(X_test_seq, maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 03:51:59.449241: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-17 03:51:59.449304: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-17 03:51:59.449335: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cluster-99b4-m): /proc/driver/nvidia/version does not exist\n",
      "2021-12-17 03:51:59.449719: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 450)          4500000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 150)               360600    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 75)                11325     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 75)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 228       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,872,153\n",
      "Trainable params: 4,872,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "316/316 - 260s - loss: 0.8701 - sparse_categorical_accuracy: 0.4970 - val_loss: 0.8452 - val_sparse_categorical_accuracy: 0.5169 - 260s/epoch - 823ms/step\n",
      "Epoch 2/10\n",
      "316/316 - 258s - loss: 0.8276 - sparse_categorical_accuracy: 0.5385 - val_loss: 0.8290 - val_sparse_categorical_accuracy: 0.5446 - 258s/epoch - 815ms/step\n",
      "Epoch 3/10\n",
      "316/316 - 256s - loss: 0.7921 - sparse_categorical_accuracy: 0.5998 - val_loss: 0.8304 - val_sparse_categorical_accuracy: 0.5348 - 256s/epoch - 809ms/step\n",
      "Epoch 4/10\n",
      "316/316 - 263s - loss: 0.7496 - sparse_categorical_accuracy: 0.6390 - val_loss: 0.8446 - val_sparse_categorical_accuracy: 0.5383 - 263s/epoch - 831ms/step\n",
      "Epoch 5/10\n",
      "316/316 - 255s - loss: 0.7055 - sparse_categorical_accuracy: 0.6634 - val_loss: 0.8600 - val_sparse_categorical_accuracy: 0.5383 - 255s/epoch - 807ms/step\n",
      "Epoch 6/10\n",
      "316/316 - 255s - loss: 0.6643 - sparse_categorical_accuracy: 0.6835 - val_loss: 0.9220 - val_sparse_categorical_accuracy: 0.5303 - 255s/epoch - 808ms/step\n",
      "Epoch 7/10\n",
      "316/316 - 257s - loss: 0.6362 - sparse_categorical_accuracy: 0.6925 - val_loss: 0.8830 - val_sparse_categorical_accuracy: 0.5419 - 257s/epoch - 813ms/step\n",
      "Epoch 8/10\n",
      "316/316 - 263s - loss: 0.6197 - sparse_categorical_accuracy: 0.6974 - val_loss: 0.9346 - val_sparse_categorical_accuracy: 0.5348 - 263s/epoch - 833ms/step\n",
      "Epoch 9/10\n",
      "316/316 - 263s - loss: 0.5969 - sparse_categorical_accuracy: 0.7050 - val_loss: 0.9386 - val_sparse_categorical_accuracy: 0.5490 - 263s/epoch - 832ms/step\n",
      "Epoch 10/10\n",
      "316/316 - 266s - loss: 0.5813 - sparse_categorical_accuracy: 0.7065 - val_loss: 0.9808 - val_sparse_categorical_accuracy: 0.5374 - 266s/epoch - 843ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f717426ea90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=(500,)))\n",
    "model.add(keras.layers.Embedding(input_dim = 10000, output_dim = 450))\n",
    "model.add(keras.layers.LSTM(150, activation='tanh'))\n",
    "model.add(keras.layers.Dense(75, activation='relu'))\n",
    "#model.add(keras.layers.Dense(50, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-3),\n",
    "    #bias_regularizer=regularizers.l2(1e-3),\n",
    "    #activity_regularizer=regularizers.l2(1e-5)))\n",
    "model.add(keras.layers.Dropout(0.05))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "model.summary()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=train_acc_metric)\n",
    "model.fit(x=X_train_seq_padded,y=y_train,batch_size=32,epochs=10,verbose=2,validation_data=(X_test_seq_padded,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 04:39:18.690583: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f717447a430> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save(filepath = \"./model\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
