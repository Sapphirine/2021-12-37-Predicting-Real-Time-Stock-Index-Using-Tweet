{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "nltk.download('punkt')\n",
    "import numpy as np\n",
    "from nltk.corpus import words\n",
    "nltk.download('words')\n",
    "from nltk.corpus import brown\n",
    "nltk.download('brown')\n",
    "from numpy import genfromtxt\n",
    "from tensorflow.keras import regularizers\n",
    "import time\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import random\n",
    "from kafka import KafkaConsumer\n",
    "import time\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "KAFKA_BOOTSTRAP_SERVER = \"localhost:9092\"\n",
    "TOPIC = \"tweets\"\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "     TOPIC,\n",
    "     bootstrap_servers=KAFKA_BOOTSTRAP_SERVER,\n",
    "#      auto_offset_reset='earliest',\n",
    "     enable_auto_commit=True)\n",
    "\n",
    "CACHE_FILE = \"cache{0}.txt\"\n",
    "TIME_INTERVEL = 60\n",
    "\n",
    "with open(\"tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(start_time)\n",
    "    data = []\n",
    "    \n",
    "    with open(CACHE_FILE.format(count), \"a\") as f:\n",
    "        for msg in consumer:\n",
    "            msg = msg.value.decode(\"utf8\")\n",
    "            f.write(msg)\n",
    "            data.append(msg)\n",
    "            f.write(\"\\n\")\n",
    "#             print(msg)\n",
    "            if time.time() >= start_time + TIME_INTERVEL:\n",
    "                ## load new model, make prediction\n",
    "                model = tf.keras.models.load_model(\"./model\")\n",
    "                with open('trend.txt', 'rb') as f:\n",
    "                    try:  # catch OSError in case of a one line file \n",
    "                        f.seek(-2, os.SEEK_END)\n",
    "                        while f.read(1) != b'\\n':\n",
    "                            f.seek(-2, os.SEEK_CUR)\n",
    "                    except OSError:\n",
    "                        f.seek(0)\n",
    "                    last_line = f.readline().decode()[:-1]\n",
    "                    ts, label = last_line.split(\",\")\n",
    "                label = int(label)\n",
    "\n",
    "                # load model\n",
    "                num_lines = len(data)\n",
    "                loaded_model = tf.keras.models.load_model(\"./model\")\n",
    "                loaded_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),loss=keras.losses.SparseCategoricalCrossentropy(),metrics=keras.metrics.SparseCategoricalAccuracy())\n",
    "                labels_array = np.ones(num_lines) * label\n",
    "\n",
    "                sequence = tokenizer.texts_to_sequences(data)\n",
    "                seq_padded = pad_sequences(sequence, maxlen=500)\n",
    "                pred = np.bincount(np.argmax(loaded_model.predict(seq_padded),axis=1)).argmax()\n",
    "                \n",
    "                print(\"predicted:  %s, actual: %s\" % (pred, label))\n",
    "                \n",
    "                count = (count + 1) % 10\n",
    "                \n",
    "                \n",
    "                break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
